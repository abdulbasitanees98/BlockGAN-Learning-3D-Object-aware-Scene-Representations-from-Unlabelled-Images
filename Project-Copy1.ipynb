{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetArray{Float32,N} where N"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet\n",
    "using AutoGrad\n",
    "using Images\n",
    "using ImageMagick\n",
    "using Random\n",
    "using PyPlot\n",
    "using Statistics\n",
    "import Base: length, size, iterate, eltype, IteratorSize, IteratorEltype, haslength, @propagate_inbounds, repeat, rand, tail\n",
    "import .Iterators: cycle, Cycle, take\n",
    "using IterTools: ncycle, takenth\n",
    "import CUDA\n",
    "array_type=(CUDA.functional() ? KnetArray{Float32} : Array{Float32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading list of images to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"GeNeVA-v1\\\\i-CLEVR\\\\images\"\n",
    "files = readdir(dataPath);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select images containing single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleObj = files[endswith.(files, \"_0.png\")]\n",
    "singleObj = [\"$(dataPath)\\\\$(file)\" for file in singleObj];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create iterator for Clevr Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ClevrData\n",
    "    files\n",
    "    batchsize::Int\n",
    "    #shuffle::Bool\n",
    "    num_instances::Int\n",
    "\n",
    "    function ClevrData(files; batchsize::Int=5) #shuffle::Bool=false)\n",
    "        new(files, batchsize, length(files))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length (generic function with 210 methods)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function length(d::ClevrData)\n",
    "    nFullBatches, rem = divrem(d.num_instances, d.batchsize)\n",
    "    nFullBatches + (rem > 0)*1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_image (generic function with 1 method)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_image(filename)\n",
    "    img = load(filename)\n",
    "    img = imresize(img, (64,64))\n",
    "    img = Float64.(channelview(img))\n",
    "    img = img[1:3,:,:]\n",
    "    img = permutedims(img, [2, 3, 1])\n",
    "#     img = reshape(img, (64,64,3,1))\n",
    "#     img = convert(array_type, img)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterate (generic function with 432 methods)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function iterate(d::ClevrData, state=collect(1:d.num_instances))\n",
    "    if length(state) > 0\n",
    "        batch = d.files[state[1:(length(state) < d.batchsize ? end : d.batchsize)]]\n",
    "        state  = state[d.batchsize+1:end]\n",
    "        out = convert(array_type, zeros(64,64,3,length(batch)))\n",
    "        ims = load_image.(batch)\n",
    "        for i in collect(1:length(batch)); out[:,:,:,i] = ims[i]; end\n",
    "        return (Param(out)), state\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1m!\u001b[22m \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mD\u001b[22m \u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1mS\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m u\u001b[0m\u001b[1ms\u001b[22min\u001b[0m\u001b[1mg\u001b[22m3\u001b[0m\u001b[1mD\u001b[22m Un\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m un\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m color\u001b[0m\u001b[1ms\u001b[22mi\u001b[0m\u001b[1mg\u001b[22mne\u001b[0m\u001b[1md\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "minimize(func, data, optimizer=Adam(); params)\n",
       "sgd     (func, data; lr=0.1,  gclip, params)\n",
       "momentum(func, data; lr=0.05, gamma=0.95, gclip, params)\n",
       "nesterov(func, data; lr=0.05, gamma=0.95, gclip, params)\n",
       "adagrad (func, data; lr=0.05, eps=1e-6, gclip, params)\n",
       "rmsprop (func, data; lr=0.01, rho=0.9, eps=1e-6, gclip, params)\n",
       "adadelta(func, data; lr=1.0,  rho=0.9, eps=1e-6, gclip, params)\n",
       "adam    (func, data; lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8, gclip, params)\n",
       "\\end{verbatim}\n",
       "Return an iterator which applies \\texttt{func} to arguments in \\texttt{data}, i.e.  \\texttt{(func(args...) for args in data)}, and updates the parameters every iteration to minimize \\texttt{func}.  \\texttt{func} should return a scalar value.\n",
       "\n",
       "The common keyword argument \\texttt{params} can be used to list the \\texttt{Param}s to be optimized.  If not specified, any \\texttt{Param} that takes part in the computation of \\texttt{func(args...)} will be updated.\n",
       "\n",
       "The common keyword argument \\texttt{gclip} can be used to implement per-parameter gradient clipping. For a parameter gradient \\texttt{g}, if \\texttt{norm(g) > gclip > 0}, \\texttt{g} is scaled so that its norm is equal to \\texttt{gclip}. If not specified no gradient clipping is performed.\n",
       "\n",
       "These functions do not perform optimization, but return an iterator that can. Any function that produces values from an iterator can be used with such an object, e.g. \\texttt{progress!(sgd(f,d))} iterates the sgd optimizer and displays a progress bar. For convenience, appending \\texttt{!} to the name of the function iterates and returns \\texttt{nothing}, i.e. \\texttt{sgd!(...)} is equivalent to \\texttt{(for x in sgd(...) end)}.\n",
       "\n",
       "We define optimizers as lazy iterators to have explicit control over them:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item To report progress use \\texttt{progress(sgd(f,d))}.\n",
       "\n",
       "\n",
       "\\item To run until convergence use \\texttt{converge(sgd(f,cycle(d)))}.\n",
       "\n",
       "\n",
       "\\item To run multiple epochs use \\texttt{sgd(f,repeat(d,n))}.\n",
       "\n",
       "\n",
       "\\item To run a given number of iterations use \\texttt{sgd(f,take(cycle(d),n))}.\n",
       "\n",
       "\n",
       "\\item To do a task every n iterations use \\texttt{(task() for (i,j) in enumerate(sgd(f,d)) if i\\%n == 1)}.\n",
       "\n",
       "\\end{itemize}\n",
       "These functions apply the same algorithm with the same configuration to every parameter by default. \\texttt{minimize} takes an explicit optimizer argument, all others call \\texttt{minimize} with an appropriate optimizer argument (see \\texttt{@doc update!} for a list of possible optimizers). Before calling \\href{@ref}{\\texttt{update!}} on a \\texttt{Param}, \\texttt{minimize} sets its \\texttt{opt} field to a copy of this default optimizer if it is not already set. The \\texttt{opt} field is used by the \\texttt{update!} function to determine the type of update performed on that parameter.  If you need finer grained control, you can set the optimizer of an individual \\texttt{Param} by setting its \\texttt{opt} field before calling one of these functions. They will not override the \\texttt{opt} field if it is already set, e.g. \\texttt{sgd(model,data)} will perform an \\texttt{Adam} update for a parameter whose \\texttt{opt} field is an \\texttt{Adam} object. This also means you can stop and start the training without losing optimization state, the first call will set the \\texttt{opt} fields and the subsequent calls will not override them.\n",
       "\n",
       "Given a parameter \\texttt{w} and its gradient \\texttt{g} here are the updates applied by each optimizer:\n",
       "\n",
       "\\begin{verbatim}\n",
       "# sgd (http://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
       "w .= w - lr * g\n",
       "\n",
       "# momentum (http://jlmelville.github.io/mize/nesterov.html)\n",
       "v .= gamma * v - lr * g\n",
       "w .= w + v\n",
       "\n",
       "# nesterov (http://jlmelville.github.io/mize/nesterov.html)\n",
       "w .= w - gamma * v\n",
       "v .= gamma * v - lr * g\n",
       "w .= w + (1 + gamma) * v\n",
       "\n",
       "# adagrad (http://www.jmlr.org/papers/v12/duchi11a.html)\n",
       "G .= G + g .^ 2\n",
       "w .= w - lr * g ./ sqrt(G + eps)\n",
       "\n",
       "# rmsprop (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
       "G .= rho * G + (1-rho) * g .^ 2 \n",
       "w .= w - lr * g ./ sqrt(G + eps)\n",
       "\n",
       "# adadelta (http://arxiv.org/abs/1212.5701)\n",
       "G .= rho * G + (1-rho) * g .^ 2\n",
       "update = sqrt(delta + eps) .* g ./ sqrt(G + eps)\n",
       "w = w - lr * update\n",
       "delta = rho * delta + (1-rho) * update .^ 2\n",
       "\n",
       "# adam (http://arxiv.org/abs/1412.6980)\n",
       "v = beta1 * v + (1 - beta1) * g\n",
       "G = beta2 * G + (1 - beta2) * g .^ 2\n",
       "vhat = v ./ (1 - beta1 ^ t)\n",
       "Ghat = G ./ (1 - beta2 ^ t)\n",
       "w = w - (lr / (sqrt(Ghat) + eps)) * vhat\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "minimize(func, data, optimizer=Adam(); params)\n",
       "sgd     (func, data; lr=0.1,  gclip, params)\n",
       "momentum(func, data; lr=0.05, gamma=0.95, gclip, params)\n",
       "nesterov(func, data; lr=0.05, gamma=0.95, gclip, params)\n",
       "adagrad (func, data; lr=0.05, eps=1e-6, gclip, params)\n",
       "rmsprop (func, data; lr=0.01, rho=0.9, eps=1e-6, gclip, params)\n",
       "adadelta(func, data; lr=1.0,  rho=0.9, eps=1e-6, gclip, params)\n",
       "adam    (func, data; lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8, gclip, params)\n",
       "```\n",
       "\n",
       "Return an iterator which applies `func` to arguments in `data`, i.e.  `(func(args...) for args in data)`, and updates the parameters every iteration to minimize `func`.  `func` should return a scalar value.\n",
       "\n",
       "The common keyword argument `params` can be used to list the `Param`s to be optimized.  If not specified, any `Param` that takes part in the computation of `func(args...)` will be updated.\n",
       "\n",
       "The common keyword argument `gclip` can be used to implement per-parameter gradient clipping. For a parameter gradient `g`, if `norm(g) > gclip > 0`, `g` is scaled so that its norm is equal to `gclip`. If not specified no gradient clipping is performed.\n",
       "\n",
       "These functions do not perform optimization, but return an iterator that can. Any function that produces values from an iterator can be used with such an object, e.g. `progress!(sgd(f,d))` iterates the sgd optimizer and displays a progress bar. For convenience, appending `!` to the name of the function iterates and returns `nothing`, i.e. `sgd!(...)` is equivalent to `(for x in sgd(...) end)`.\n",
       "\n",
       "We define optimizers as lazy iterators to have explicit control over them:\n",
       "\n",
       "  * To report progress use `progress(sgd(f,d))`.\n",
       "  * To run until convergence use `converge(sgd(f,cycle(d)))`.\n",
       "  * To run multiple epochs use `sgd(f,repeat(d,n))`.\n",
       "  * To run a given number of iterations use `sgd(f,take(cycle(d),n))`.\n",
       "  * To do a task every n iterations use `(task() for (i,j) in enumerate(sgd(f,d)) if i%n == 1)`.\n",
       "\n",
       "These functions apply the same algorithm with the same configuration to every parameter by default. `minimize` takes an explicit optimizer argument, all others call `minimize` with an appropriate optimizer argument (see `@doc update!` for a list of possible optimizers). Before calling [`update!`](@ref) on a `Param`, `minimize` sets its `opt` field to a copy of this default optimizer if it is not already set. The `opt` field is used by the `update!` function to determine the type of update performed on that parameter.  If you need finer grained control, you can set the optimizer of an individual `Param` by setting its `opt` field before calling one of these functions. They will not override the `opt` field if it is already set, e.g. `sgd(model,data)` will perform an `Adam` update for a parameter whose `opt` field is an `Adam` object. This also means you can stop and start the training without losing optimization state, the first call will set the `opt` fields and the subsequent calls will not override them.\n",
       "\n",
       "Given a parameter `w` and its gradient `g` here are the updates applied by each optimizer:\n",
       "\n",
       "```\n",
       "# sgd (http://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
       "w .= w - lr * g\n",
       "\n",
       "# momentum (http://jlmelville.github.io/mize/nesterov.html)\n",
       "v .= gamma * v - lr * g\n",
       "w .= w + v\n",
       "\n",
       "# nesterov (http://jlmelville.github.io/mize/nesterov.html)\n",
       "w .= w - gamma * v\n",
       "v .= gamma * v - lr * g\n",
       "w .= w + (1 + gamma) * v\n",
       "\n",
       "# adagrad (http://www.jmlr.org/papers/v12/duchi11a.html)\n",
       "G .= G + g .^ 2\n",
       "w .= w - lr * g ./ sqrt(G + eps)\n",
       "\n",
       "# rmsprop (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
       "G .= rho * G + (1-rho) * g .^ 2 \n",
       "w .= w - lr * g ./ sqrt(G + eps)\n",
       "\n",
       "# adadelta (http://arxiv.org/abs/1212.5701)\n",
       "G .= rho * G + (1-rho) * g .^ 2\n",
       "update = sqrt(delta + eps) .* g ./ sqrt(G + eps)\n",
       "w = w - lr * update\n",
       "delta = rho * delta + (1-rho) * update .^ 2\n",
       "\n",
       "# adam (http://arxiv.org/abs/1412.6980)\n",
       "v = beta1 * v + (1 - beta1) * g\n",
       "G = beta2 * G + (1 - beta2) * g .^ 2\n",
       "vhat = v ./ (1 - beta1 ^ t)\n",
       "Ghat = G ./ (1 - beta2 ^ t)\n",
       "w = w - (lr / (sqrt(Ghat) + eps)) * vhat\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  minimize(func, data, optimizer=Adam(); params)\u001b[39m\n",
       "\u001b[36m  sgd     (func, data; lr=0.1,  gclip, params)\u001b[39m\n",
       "\u001b[36m  momentum(func, data; lr=0.05, gamma=0.95, gclip, params)\u001b[39m\n",
       "\u001b[36m  nesterov(func, data; lr=0.05, gamma=0.95, gclip, params)\u001b[39m\n",
       "\u001b[36m  adagrad (func, data; lr=0.05, eps=1e-6, gclip, params)\u001b[39m\n",
       "\u001b[36m  rmsprop (func, data; lr=0.01, rho=0.9, eps=1e-6, gclip, params)\u001b[39m\n",
       "\u001b[36m  adadelta(func, data; lr=1.0,  rho=0.9, eps=1e-6, gclip, params)\u001b[39m\n",
       "\u001b[36m  adam    (func, data; lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8, gclip, params)\u001b[39m\n",
       "\n",
       "  Return an iterator which applies \u001b[36mfunc\u001b[39m to arguments in \u001b[36mdata\u001b[39m, i.e.\n",
       "  \u001b[36m(func(args...) for args in data)\u001b[39m, and updates the parameters every iteration\n",
       "  to minimize \u001b[36mfunc\u001b[39m. \u001b[36mfunc\u001b[39m should return a scalar value.\n",
       "\n",
       "  The common keyword argument \u001b[36mparams\u001b[39m can be used to list the \u001b[36mParam\u001b[39ms to be\n",
       "  optimized. If not specified, any \u001b[36mParam\u001b[39m that takes part in the computation of\n",
       "  \u001b[36mfunc(args...)\u001b[39m will be updated.\n",
       "\n",
       "  The common keyword argument \u001b[36mgclip\u001b[39m can be used to implement per-parameter\n",
       "  gradient clipping. For a parameter gradient \u001b[36mg\u001b[39m, if \u001b[36mnorm(g) > gclip > 0\u001b[39m, \u001b[36mg\u001b[39m is\n",
       "  scaled so that its norm is equal to \u001b[36mgclip\u001b[39m. If not specified no gradient\n",
       "  clipping is performed.\n",
       "\n",
       "  These functions do not perform optimization, but return an iterator that\n",
       "  can. Any function that produces values from an iterator can be used with\n",
       "  such an object, e.g. \u001b[36mprogress!(sgd(f,d))\u001b[39m iterates the sgd optimizer and\n",
       "  displays a progress bar. For convenience, appending \u001b[36m!\u001b[39m to the name of the\n",
       "  function iterates and returns \u001b[36mnothing\u001b[39m, i.e. \u001b[36msgd!(...)\u001b[39m is equivalent to \u001b[36m(for\n",
       "  x in sgd(...) end)\u001b[39m.\n",
       "\n",
       "  We define optimizers as lazy iterators to have explicit control over them:\n",
       "\n",
       "    •    To report progress use \u001b[36mprogress(sgd(f,d))\u001b[39m.\n",
       "\n",
       "    •    To run until convergence use \u001b[36mconverge(sgd(f,cycle(d)))\u001b[39m.\n",
       "\n",
       "    •    To run multiple epochs use \u001b[36msgd(f,repeat(d,n))\u001b[39m.\n",
       "\n",
       "    •    To run a given number of iterations use \u001b[36msgd(f,take(cycle(d),n))\u001b[39m.\n",
       "\n",
       "    •    To do a task every n iterations use \u001b[36m(task() for (i,j) in\n",
       "        enumerate(sgd(f,d)) if i%n == 1)\u001b[39m.\n",
       "\n",
       "  These functions apply the same algorithm with the same configuration to\n",
       "  every parameter by default. \u001b[36mminimize\u001b[39m takes an explicit optimizer argument,\n",
       "  all others call \u001b[36mminimize\u001b[39m with an appropriate optimizer argument (see \u001b[36m@doc\n",
       "  update!\u001b[39m for a list of possible optimizers). Before calling \u001b[36mupdate!\u001b[39m on a\n",
       "  \u001b[36mParam\u001b[39m, \u001b[36mminimize\u001b[39m sets its \u001b[36mopt\u001b[39m field to a copy of this default optimizer if it\n",
       "  is not already set. The \u001b[36mopt\u001b[39m field is used by the \u001b[36mupdate!\u001b[39m function to\n",
       "  determine the type of update performed on that parameter. If you need finer\n",
       "  grained control, you can set the optimizer of an individual \u001b[36mParam\u001b[39m by setting\n",
       "  its \u001b[36mopt\u001b[39m field before calling one of these functions. They will not override\n",
       "  the \u001b[36mopt\u001b[39m field if it is already set, e.g. \u001b[36msgd(model,data)\u001b[39m will perform an\n",
       "  \u001b[36mAdam\u001b[39m update for a parameter whose \u001b[36mopt\u001b[39m field is an \u001b[36mAdam\u001b[39m object. This also\n",
       "  means you can stop and start the training without losing optimization state,\n",
       "  the first call will set the \u001b[36mopt\u001b[39m fields and the subsequent calls will not\n",
       "  override them.\n",
       "\n",
       "  Given a parameter \u001b[36mw\u001b[39m and its gradient \u001b[36mg\u001b[39m here are the updates applied by each\n",
       "  optimizer:\n",
       "\n",
       "\u001b[36m  # sgd (http://en.wikipedia.org/wiki/Stochastic_gradient_descent)\u001b[39m\n",
       "\u001b[36m  w .= w - lr * g\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # momentum (http://jlmelville.github.io/mize/nesterov.html)\u001b[39m\n",
       "\u001b[36m  v .= gamma * v - lr * g\u001b[39m\n",
       "\u001b[36m  w .= w + v\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # nesterov (http://jlmelville.github.io/mize/nesterov.html)\u001b[39m\n",
       "\u001b[36m  w .= w - gamma * v\u001b[39m\n",
       "\u001b[36m  v .= gamma * v - lr * g\u001b[39m\n",
       "\u001b[36m  w .= w + (1 + gamma) * v\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # adagrad (http://www.jmlr.org/papers/v12/duchi11a.html)\u001b[39m\n",
       "\u001b[36m  G .= G + g .^ 2\u001b[39m\n",
       "\u001b[36m  w .= w - lr * g ./ sqrt(G + eps)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # rmsprop (http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\u001b[39m\n",
       "\u001b[36m  G .= rho * G + (1-rho) * g .^ 2 \u001b[39m\n",
       "\u001b[36m  w .= w - lr * g ./ sqrt(G + eps)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # adadelta (http://arxiv.org/abs/1212.5701)\u001b[39m\n",
       "\u001b[36m  G .= rho * G + (1-rho) * g .^ 2\u001b[39m\n",
       "\u001b[36m  update = sqrt(delta + eps) .* g ./ sqrt(G + eps)\u001b[39m\n",
       "\u001b[36m  w = w - lr * update\u001b[39m\n",
       "\u001b[36m  delta = rho * delta + (1-rho) * update .^ 2\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  # adam (http://arxiv.org/abs/1412.6980)\u001b[39m\n",
       "\u001b[36m  v = beta1 * v + (1 - beta1) * g\u001b[39m\n",
       "\u001b[36m  G = beta2 * G + (1 - beta2) * g .^ 2\u001b[39m\n",
       "\u001b[36m  vhat = v ./ (1 - beta1 ^ t)\u001b[39m\n",
       "\u001b[36m  Ghat = G ./ (1 - beta2 ^ t)\u001b[39m\n",
       "\u001b[36m  w = w - (lr / (sqrt(Ghat) + eps)) * vhat\u001b[39m"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?sgd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in clevrDataset\n",
    "#     println(length(batch))\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leakyRelu (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function leakyRelu(x)\n",
    "    max(0.1 .* x, x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Z(dim1, dim2)\n",
    "    z = (rand(dim1, dim2).*2.0).-1.0\n",
    "    convert(array_type, z)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z2 (generic function with 2 methods)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Z2(dim1, dim2, dim3, dim4)\n",
    "    z = (rand(dim1, dim2, dim3, dim4).*2.0).-1.0\n",
    "    convert(array_type, z)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Z3 (generic function with 1 method)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Z3(dim1, dim2, dim3, dim4, dim5)\n",
    "    z = (rand(dim1, dim2, dim3, dim4, dim5).*2.0).-1.0\n",
    "    convert(array_type, z)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Discriminator2\n",
    "    layers\n",
    "    Discriminator2(layers...) = new(layers)\n",
    "end\n",
    "(model::Discriminator2)(x) = (for l in model.layers; x = l(x); end; x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Generator2\n",
    "    layers\n",
    "    Generator2(layers...) = new(layers)\n",
    "end\n",
    "# (model::Generator2)(x) = (for l in model.layers; x = l(x); end; x)\n",
    "function (model::Generator2)(z)\n",
    "    layers = model.layers\n",
    "    x = layers[1]()\n",
    "    for i in collect(2:length(layers))\n",
    "       x = layers[i](x) \n",
    "    end\n",
    "    x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ObjectGenerator\n",
    "    layers\n",
    "    ObjectGenerator(layers...) = new(layers)\n",
    "end\n",
    "(model::ObjectGenerator)(x) = (for l in model.layers; x = l(x); end; x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct BackgroundGenerator\n",
    "    layers\n",
    "    BackgroundGenerator(layers...) = new(layers)\n",
    "end\n",
    "(model::BackgroundGenerator)(x) = (for l in model.layers; x = l(x); end; x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dLoss(D::Discriminator2, realIms, fakeIms)\n",
    "    realLoss = -mean(log.(D(realIms)))\n",
    "    fakeLoss = -mean(log.(1 .- D(fakeIms)))\n",
    "    return 0.5*(realLoss+fakeLoss)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gLoss(G::Generator2, D::Discriminator2, z)\n",
    "    yPr = D(G(z))\n",
    "    return -0.5*mean(log.(yPr))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Chain\n",
    "    layers\n",
    "    Chain(layers...) = new(layers)\n",
    "end\n",
    "(model::Chain)(x) = (for l in model.layers; x = l(x); end; x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Dense; w; b; f; end\n",
    "Dense(i::Int,o::Int,f=relu) = Dense(param(o,i), param0(o), f)\n",
    "(d::Dense)(x) = d.f.(d.w * mat(x) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix so we can use matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Reshape1; x; y; c; end;\n",
    "Reshape1() = Reshape1(64,64,3)\n",
    "(r::Reshape1)(x) = reshape(x, r.x, r.y, r.c, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Reshape3; x; y; c; end;\n",
    "Reshape3() = Reshape3(64,64,3)\n",
    "(r::Reshape3)(x) = reshape(x, r.x, r.y, r.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Reshape2; a end;\n",
    "Reshape2() = Reshape2(1)\n",
    "(r::Reshape2)(x) = reshape(x, :,size(x)[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct BNorm; moments; params; act; end;\n",
    "(bn::BNorm)(x) = if bn.act sigm.(batchnorm(x, bn.moments, bn.params)) else batchnorm(x, bn.moments, bn.params) end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Conv; w; b; f; end\n",
    "(c::Conv)(x) = c.f.(conv4(c.w, x, stride = 2, padding = 2) .+ c.b)\n",
    "Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=leakyRelu) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deconv"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Deconv; w; f; end\n",
    "(c::Deconv)(x) = c.f.(deconv4(c.w, x, padding = 0, stride = 1))\n",
    "Deconv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu) = Deconv(param(w1,w2,cx,cy),f)\n",
    "Deconv(w1::Int,w2::Int,w3::Int,cx::Int,cy::Int,f=relu) = Deconv(param(w1,w2,w3,cx,cy),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deconv2"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Deconv2; w; f; end\n",
    "(c::Deconv2)(x) = c.f.(deconv4(c.w, x, padding = 1, stride = 2))\n",
    "Deconv2(w1::Int,w2::Int,cx::Int,cy::Int,f=relu) = Deconv2(param(w1,w2,cx,cy),f)\n",
    "Deconv2(w1::Int,w2::Int,w3::Int,cx::Int,cy::Int,f=relu) = Deconv2(param(w1,w2,w3,cx,cy),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deconv3"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Deconv3; w; f; end\n",
    "(c::Deconv3)(x) = c.f.(deconv4(c.w, x, padding = 2, stride = 1))\n",
    "Deconv3(w1::Int,w2::Int,cx::Int,cy::Int,f=relu) = Deconv3(param(w1,w2,cx,cy),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function unpack(array)\n",
    "#     objs = size(array)[end]\n",
    "#     if objs > 1\n",
    "#         out = [x[:,:,:,:,i]\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SceneComposer (generic function with 2 methods)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SceneComposer(objs...)\n",
    "    m  = max.(objs)\n",
    "    concat = reshape(m, (16,16,16*64,:))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "createScene (generic function with 1 method)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createScene(bgTensor, fgTensor)\n",
    "    FG = ObjectGenerator(Deconv2(4,4,4,128,512), Deconv2(4,4,4,64,128))\n",
    "    BG = BackgroundGenerator(Deconv2(4,4,4,128,256), Deconv2(4,4,4,64,128))\n",
    "    f  = FG(fgTensor)\n",
    "    b  = BG(bgTensor)\n",
    "    SceneComposer(f,b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Scene\n",
    "    l1\n",
    "    l2\n",
    "end\n",
    "Scene(b::Int,f::Int) = Scene(param(4,4,4,b,1), param(4,4,4,f,1))\n",
    "(s::Scene)() = createScene(s.l1, s.l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator2((Conv(P(KnetArray{Float32,4}(5,5,3,64)), P(KnetArray{Float32,4}(1,1,64,1)), leakyRelu), Conv(P(KnetArray{Float32,4}(5,5,64,128)), P(KnetArray{Float32,4}(1,1,128,1)), leakyRelu), Conv(P(KnetArray{Float32,4}(5,5,128,256)), P(KnetArray{Float32,4}(1,1,256,1)), leakyRelu), Conv(P(KnetArray{Float32,4}(5,5,256,512)), P(KnetArray{Float32,4}(1,1,512,1)), leakyRelu), Dense(P(KnetArray{Float32,2}(1,8192)), P(KnetArray{Float32,1}(1)), Knet.Ops20.sigm)))"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(1234)\n",
    "loss_g = []\n",
    "loss_d = []\n",
    "\n",
    "G = Generator2(Scene(256, 512), Deconv(1,1,64,16*64), Deconv2(4,4,64,64), Deconv2(4,4,64,64), Deconv3(5,5,3,64))\n",
    "D = Discriminator2(Conv(5,5,3,64), Conv(5,5,64,128), Conv(5,5,128,256), Conv(5,5,256,512), Dense(4*4*512,1,sigm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1m4\u001b[22m \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m3 \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m2 \u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m space\u001b[0m\u001b[1md\u001b[22mir\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mc\u001b[22mti\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22ms gol\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1me\u001b[22mnse\u001b[0m\u001b[1mc\u001b[22mti\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "deconv4(w, x; kwargs...)\n",
       "\\end{verbatim}\n",
       "Simulate 4-D deconvolution by using \\emph{transposed convolution} operation. Its forward pass is equivalent to backward pass of a convolution (gradients with respect to input tensor). Likewise, its backward pass (gradients with respect to input tensor) is equivalent to forward pass of a convolution. Since it swaps forward and backward passes of convolution operation, padding and stride options belong to output tensor. See \\href{https://arxiv.org/abs/1603.07285}{this report} for further explanation.\n",
       "\n",
       "If \\texttt{w} has dimensions \\texttt{(W1,W2,...,Cy,Cx)} and \\texttt{x} has dimensions \\texttt{(X1,X2,...,Cx,N)}, the result \\texttt{y=deconv4(w,x)} will have dimensions \\texttt{(Y1,Y2,...,Cy,N)} where\n",
       "\n",
       "\\begin{verbatim}\n",
       "Yi = (Xi - 1)*stride[i] + ((Wi-1)*dilation[i] + 1) - 2*padding[i]\n",
       "\\end{verbatim}\n",
       "Here Cx is the number of x channels, Cy is the number of y channels, N is the number of instances, and Wi,Xi,Yi are spatial dimensions. Padding and stride are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "\\section{Keywords}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{padding=0}: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "\n",
       "\n",
       "\\item \\texttt{stride=1}: the number of elements to slide to reach the next filtering window.\n",
       "\n",
       "\n",
       "\\item \\texttt{mode=0}: 0 for convolution and 1 for cross-correlation.\n",
       "\n",
       "\n",
       "\\item \\texttt{alpha=1}: can be used to scale the result.\n",
       "\n",
       "\n",
       "\\item \\texttt{handle}: handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n",
       "\n",
       "\n",
       "\\item \\texttt{group=1}: can be used to perform grouped convolutions.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "deconv4(w, x; kwargs...)\n",
       "```\n",
       "\n",
       "Simulate 4-D deconvolution by using *transposed convolution* operation. Its forward pass is equivalent to backward pass of a convolution (gradients with respect to input tensor). Likewise, its backward pass (gradients with respect to input tensor) is equivalent to forward pass of a convolution. Since it swaps forward and backward passes of convolution operation, padding and stride options belong to output tensor. See [this report](https://arxiv.org/abs/1603.07285) for further explanation.\n",
       "\n",
       "If `w` has dimensions `(W1,W2,...,Cy,Cx)` and `x` has dimensions `(X1,X2,...,Cx,N)`, the result `y=deconv4(w,x)` will have dimensions `(Y1,Y2,...,Cy,N)` where\n",
       "\n",
       "```\n",
       "Yi = (Xi - 1)*stride[i] + ((Wi-1)*dilation[i] + 1) - 2*padding[i]\n",
       "```\n",
       "\n",
       "Here Cx is the number of x channels, Cy is the number of y channels, N is the number of instances, and Wi,Xi,Yi are spatial dimensions. Padding and stride are keyword arguments that can be specified as a single number (in which case they apply to all dimensions), or an array/tuple with entries for each spatial dimension.\n",
       "\n",
       "# Keywords\n",
       "\n",
       "  * `padding=0`: the number of extra zeros implicitly concatenated at the start and at the end of each dimension.\n",
       "  * `stride=1`: the number of elements to slide to reach the next filtering window.\n",
       "  * `mode=0`: 0 for convolution and 1 for cross-correlation.\n",
       "  * `alpha=1`: can be used to scale the result.\n",
       "  * `handle`: handle to a previously created cuDNN context. Defaults to a Knet allocated handle.\n",
       "  * `group=1`: can be used to perform grouped convolutions.\n"
      ],
      "text/plain": [
       "\u001b[36m  deconv4(w, x; kwargs...)\u001b[39m\n",
       "\n",
       "  Simulate 4-D deconvolution by using \u001b[4mtransposed convolution\u001b[24m operation. Its\n",
       "  forward pass is equivalent to backward pass of a convolution (gradients with\n",
       "  respect to input tensor). Likewise, its backward pass (gradients with\n",
       "  respect to input tensor) is equivalent to forward pass of a convolution.\n",
       "  Since it swaps forward and backward passes of convolution operation, padding\n",
       "  and stride options belong to output tensor. See this report\n",
       "  (https://arxiv.org/abs/1603.07285) for further explanation.\n",
       "\n",
       "  If \u001b[36mw\u001b[39m has dimensions \u001b[36m(W1,W2,...,Cy,Cx)\u001b[39m and \u001b[36mx\u001b[39m has dimensions \u001b[36m(X1,X2,...,Cx,N)\u001b[39m,\n",
       "  the result \u001b[36my=deconv4(w,x)\u001b[39m will have dimensions \u001b[36m(Y1,Y2,...,Cy,N)\u001b[39m where\n",
       "\n",
       "\u001b[36m  Yi = (Xi - 1)*stride[i] + ((Wi-1)*dilation[i] + 1) - 2*padding[i]\u001b[39m\n",
       "\n",
       "  Here Cx is the number of x channels, Cy is the number of y channels, N is\n",
       "  the number of instances, and Wi,Xi,Yi are spatial dimensions. Padding and\n",
       "  stride are keyword arguments that can be specified as a single number (in\n",
       "  which case they apply to all dimensions), or an array/tuple with entries for\n",
       "  each spatial dimension.\n",
       "\n",
       "\u001b[1m  Keywords\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •    \u001b[36mpadding=0\u001b[39m: the number of extra zeros implicitly concatenated at\n",
       "        the start and at the end of each dimension.\n",
       "\n",
       "    •    \u001b[36mstride=1\u001b[39m: the number of elements to slide to reach the next\n",
       "        filtering window.\n",
       "\n",
       "    •    \u001b[36mmode=0\u001b[39m: 0 for convolution and 1 for cross-correlation.\n",
       "\n",
       "    •    \u001b[36malpha=1\u001b[39m: can be used to scale the result.\n",
       "\n",
       "    •    \u001b[36mhandle\u001b[39m: handle to a previously created cuDNN context. Defaults to\n",
       "        a Knet allocated handle.\n",
       "\n",
       "    •    \u001b[36mgroup=1\u001b[39m: can be used to perform grouped convolutions."
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?deconv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLoss(D, i, G(z)) = 0.6953708529472351\n",
      "dLoss(D, i, G(z)) = 0.490739107131958\n",
      "dLoss(D, i, G(z)) = 0.5471761226654053\n",
      "dLoss(D, i, G(z)) = 0.15956293046474457\n",
      "dLoss(D, i, G(z)) = 1.9275312423706055\n",
      "dLoss(D, i, G(z)) = 0.030199842527508736\n",
      "dLoss(D, i, G(z)) = 0.03598947077989578\n",
      "dLoss(D, i, G(z)) = 0.019018832594156265\n",
      "dLoss(D, i, G(z)) = 0.003919986076653004\n",
      "dLoss(D, i, G(z)) = 0.0003582388162612915\n",
      "dLoss(D, i, G(z)) = 1.5206959687930066e-5\n",
      "dLoss(D, i, G(z)) = 3.6266439451537735e-7\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0\n",
      "dLoss(D, i, G(z)) = -0.0"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled)) at .\\task.jl:656",
      " [2] wait at .\\task.jl:713 [inlined]",
      " [3] uv_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:933",
      " [4] unsafe_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:1005",
      " [5] unsafe_write at .\\io.jl:337 [inlined]",
      " [6] write at .\\strings\\io.jl:183 [inlined]",
      " [7] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String) at .\\strings\\io.jl:185",
      " [8] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::String, ::Vararg{Any,N} where N) at .\\strings\\io.jl:46",
      " [9] println(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::String, ::Vararg{String,N} where N) at .\\strings\\io.jl:73",
      " [10] println(::String, ::String) at .\\coreio.jl:4",
      " [11] top-level scope at .\\In[447]:3",
      " [12] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091",
      " [13] execute_code(::String, ::String) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\execute_request.jl:27",
      " [14] execute_request(::ZMQ.Socket, ::IJulia.Msg) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\execute_request.jl:86",
      " [15] #invokelatest#1 at .\\essentials.jl:710 [inlined]",
      " [16] invokelatest at .\\essentials.jl:709 [inlined]",
      " [17] eventloop(::ZMQ.Socket) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\eventloop.jl:8",
      " [18] (::IJulia.var\"#15#18\")() at .\\task.jl:356"
     ]
    }
   ],
   "source": [
    "# for i in ncycle(take(clevrDataset1,20), 100)\n",
    "#     z = Z2(16,16,16*64,1)\n",
    "#     @show dLoss(D, i, G(z))\n",
    "# #     adam!(gLoss, [(G, D, z)], params=params(G))\n",
    "#     adam!(dLoss, [(D, i, G(z))])#, params=params(D))\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main()\n",
    "    clevrDataset = ClevrData(singleObj)\n",
    "#     G = Generator2(Dense(128, 12288), Reshape1())\n",
    "#     D = Discriminator2(Reshape2(), Dense(12288, 1, sigm))\n",
    "#     loss_g = []\n",
    "#     loss_d = []\n",
    "    i = 1\n",
    "    for real_image in ncycle(take(clevrDataset,20), 100)\n",
    "        z = Z2(16,16,16*64,1)\n",
    "        if i % 25 == 0\n",
    "        adam!(dLoss, [(D, real_image, G(z))])#, params=params(D))\n",
    "        end\n",
    "#         if i % 5 == 0\n",
    "        adam!(gLoss, [(G, D, z)], params=params(G))\n",
    "#         end\n",
    "        if i % 100 == 0\n",
    "            push!(loss_g, gLoss(G, D, z))\n",
    "            push!(loss_d, dLoss(D, real_image, G(z)))\n",
    "            print(\"$(i): GenLoss: \");print(loss_g[end])\n",
    "            print(\"    DisLoss: \");println(loss_d[end])\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: GenLoss: 9.027029037475586"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled)) at .\\task.jl:656",
      " [2] wait at .\\task.jl:713 [inlined]",
      " [3] uv_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:933",
      " [4] unsafe_write(::Base.PipeEndpoint, ::Ptr{UInt8}, ::UInt64) at .\\stream.jl:1005",
      " [5] unsafe_write at .\\io.jl:337 [inlined]",
      " [6] unsafe_write at .\\io.jl:622 [inlined]",
      " [7] write at .\\io.jl:645 [inlined]",
      " [8] show(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Float64, ::Bool, ::Bool) at .\\ryu\\Ryu.jl:117",
      " [9] show at .\\ryu\\Ryu.jl:112 [inlined]",
      " [10] print(::IJulia.IJuliaStdio{Base.PipeEndpoint}, ::Float64) at .\\strings\\io.jl:35",
      " [11] print(::Float64) at .\\coreio.jl:3",
      " [12] main() at .\\In[480]:19",
      " [13] top-level scope at In[481]:2",
      " [14] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091",
      " [15] execute_code(::String, ::String) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\execute_request.jl:27",
      " [16] execute_request(::ZMQ.Socket, ::IJulia.Msg) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\execute_request.jl:86",
      " [17] #invokelatest#1 at .\\essentials.jl:710 [inlined]",
      " [18] invokelatest at .\\essentials.jl:709 [inlined]",
      " [19] eventloop(::ZMQ.Socket) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\eventloop.jl:8",
      " [20] eventloop(::ZMQ.Socket) at C:\\Users\\basit\\.julia\\packages\\IJulia\\rWZ9e\\src\\eventloop.jl:28 (repeats 3 times)",
      " [21] (::IJulia.var\"#15#18\")() at .\\task.jl:356"
     ]
    }
   ],
   "source": [
    "Random.seed!(123678)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x000000009A911A00>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = G(Z2(16,16,16*64,1))[:,:,:,1]\n",
    "img = convert(Array{Float32}, value(img))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img ./ maximum(img);\n",
    "#imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <Figure size 640x480 with 1 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x0000000063D62460>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clevrDataset1 = ClevrData(singleObj)1\n",
    "img1= first(take(clevrDataset1, 1))[:,:,:,1]\n",
    "img1 = convert(Array{Float32}, value(img1))\n",
    "imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 KnetArray{Float32,2}:\n",
       " 0.49700376"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(first(take(clevrDataset1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Deconv2(4,4,4,128,512)\n",
    "# a(param(4,4,4,512,1))\n",
    "# b = Deconv2(4,4,4,64,128)\n",
    "# b(a(param(4,4,4,512,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = ObjectGenerator()\n",
    "# foreground = ObjectGenerator()\n",
    "# composedScene = max.(background, foreground)\n",
    "# concat = reshape(composedScene, (16,16,16*64,1))\n",
    "# c1 = Conv(1,1,1024,64)\n",
    "# projected = c1(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random.seed!(1234)\n",
    "# loss_g = []\n",
    "# loss_d = []\n",
    "# moments1 = bnmoments()\n",
    "# params1 = param(bnparams(3))\n",
    "# G = Generator2(Dense(128, 12288, sigm), Reshape1())\n",
    "# D = Discriminator2(Conv(5,5,3,64,leakyRelu), Dense(65536, 1, sigm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Conv(5,5,3,64)\n",
    "# b = Conv(5,5,64,128)\n",
    "# c = Conv(5,5,128,256)\n",
    "# d = Conv(5,5,256,512)\n",
    "# e = Dense(4*4*512,1,sigm)\n",
    "# e(d(c(b(a(param(64,64,3,1))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Conv(1,1,1024,64)\n",
    "# a(param(randn(16,16,1024,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = a(Z2(16,16,16*64,1))\n",
    "# f = b(e)\n",
    "# g = b(f)\n",
    "# h = c(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Deconv2(4,4,64,16*64)\n",
    "\n",
    "# a(param(16,16,16*64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = randn(16, 16, 16*64, 1)\n",
    "# w = randn(4, 4, 64, 16*64)\n",
    "# y = deconv4(w, x, stride = 2, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 3\n",
    "# a(param(randn(16,16,1024,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Deconv(1,1,64,16*64)\n",
    "# a(param(16,16,16*64,1))\n",
    "# b = Deconv2(4,4,64,64)\n",
    "# b(b(param(16,16,64,1)))\n",
    "# c = Deconv3(5,5,3,64)\n",
    "# c(param(64,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function make_minibatch(names, batchSize = 128)\n",
    "#     rem = mod(length(names), batchSize)\n",
    "#     names = reshape(names[1:end-rem], :, batchSize)\n",
    "# end\n",
    "\n",
    "# batches = make_minibatch(singleObj, 64)\n",
    "# batch = load_batch(batches, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
